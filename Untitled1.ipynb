{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0318c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Clear the session and reset default graph\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Define image shape\n",
    "img_shape = (224, 224, 3)\n",
    "\n",
    "# Load train_df, valid_df, and test_df DataFrames from CSV files\n",
    "train_df = pd.read_csv(r\"C:\\Users\\Admin8\\Desktop\\NTU\\Project\\ProjectCode\\augmented_train_df.csv\")\n",
    "valid_df = pd.read_csv(r\"C:\\Users\\Admin8\\Desktop\\NTU\\Project\\ProjectCode\\valid_split_df.csv\")\n",
    "test_df = pd.read_csv(r\"C:\\Users\\Admin8\\Desktop\\NTU\\Project\\ProjectCode\\test_split_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19bd187",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mK\u001b[49m\u001b[38;5;241m.\u001b[39mclear_session() \u001b[38;5;66;03m#clear the session\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mreset_default_graph()\n\u001b[0;32m      3\u001b[0m img_shape\u001b[38;5;241m=\u001b[39m(img_size[\u001b[38;5;241m0\u001b[39m], img_size[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "K.clear_session() #clear the session\n",
    "tf.compat.v1.reset_default_graph()\n",
    "img_shape=(img_size[0], img_size[1], 3)\n",
    "model_name='EfficientNetB5'\n",
    "base_model=tf.keras.applications.efficientnet.EfficientNetB5(include_top=False, weights=\"imagenet\",input_shape=img_shape, pooling='max') \n",
    "# Note you are always told NOT to make the base model trainable initially- that is WRONG you get better results leaving it trainable\n",
    "base_model.trainable=True\n",
    "x=base_model.output\n",
    "x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n",
    "                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n",
    "x=Dropout(rate=.4, seed=123)(x)       \n",
    "output=Dense(class_count, activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input, outputs=output)\n",
    "lr=.001 # start with this learning rate\n",
    "model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53bcea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
